# 180530  

### Hadoop  
대용량 데이터를 분산 처리할 수 있는 자바 기반의 오픈소스 프레임워크  
분산 파일 시스템인 HDFS에 데이터 저장  
분산 처리 시스템인 MapReduce를 통해 데이터를 처리  

병렬로 하드웨어를 무한대로 늘릴 수 있는 장점  
-> 작업하다가 데이터 용량이 모자라면 리눅스 서버만 필요한 만큼 추가하면 된다.  
-> 아주 큰 데이터를 다룰 수 있게 해 준다.

#### Hadoop Ecosystem  
다양한 서브 프로젝트들 
- 분산 코디네이터 : Zookeeper
- 리소스 관리 : YARN, Mesos
- 데이터 저장 : HBase, Kudu
- 데이터 수집 : Chukwa, Flume, Scribe, Sqoop, Hiho, Kafka
- 데이터 처리 : Pig, Mahout, Spark, Impala, Presto, Hive, Tajo
- 워크플로우 관리 : Oozie, Airflow, Azkaban, Nifi
- 데이터 시각화 : Zeppelin

#### Hadoop은 RDBMS와 상호보완적이다  
기존 RDBMS를 대체하지 않는다  
Hadoop은 트랜잭션이나 무결성이 반드시 보장되어야 하는 데이터를 처리하는 데 적합하지 않음  

### Hadoop 설치  
1. Hadoop  
  1. 설치 위치 : /usr/local/
  2. 환경설정  
     1. 시스템 환경설정 : /etc/environment  
     2. Hadoop 환경설정 : /usr/local/hadoop/etc/hadoop  
			  core-site.xml : HDFS, MapReduce에 공통적으로 사용할 환경정보 설정  
			  hdfs-site.xml : HDFS에서 사용할 환경정보  
			  mapred-site.xml : MapReduce에서 사용할 환경정보  
			  yarn-site.xml  
		  	  hadoop-env.sh : Hadoop 실행하는 셸 스크립트 파일에서 필요한 환경변수  
2. JDK  
3. Hadoop 설치 모드 
    1. 독립 모드  
    2. 가상 분산 모드 >> 지금  
    3. 완전 분산 모드 >> 나중에(조별로)   


#### 터미널에서 다운로드 
우리는 2.7.5 버전으로 설치했다!  
```
wget http://apache.tt.co.kr/hadoop/common/hadoop-2.7.6/hadoop-2.7.6.tar.gz 
```

#### 시스템 환경설정  
먼저 인코딩 UTF-8인지, java 설치되어 있는지 확인  
```
echo $LANG
java -version
```

압축 풀고 hadoop-2.7.5 폴더를 /usr/local로 옮기기  

```
tar xvfz hadoop-2.7.5.tar.gz
sudo mv hadoop-2.7.5 /usr/local/
cd /usr/local/
```

링크 만들기  
```
sudo ln -s hadoop-2.7.5 hadoop
```
  
```
lrwxrwxrwx  1 root root   12  5월 30 10:18 hadoop -> hadoop-2.7.5/
```

etc/environment 편집하기  

```
sudo gedit /etc/environment
```

```
PATH=".:/usr/local/hadoop/bin:/usr/local/hadoop/sbin:/usr/local/jdk1.8.0_171/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games"

JAVA_HOME="/usr/local/jdk_1.8.0_171"

CLASSPATH=$JAVA_HOME/lib:home/sist/hadoop_user_jar

HADOOP_HOME="/usr/local/hadoop"
HADOOP_MAPRED_HOME="/usr/local/hadoop"
HADOOP_COMMON_HOME="/usr/local/hadoop"
HADOOP_HDFS_HOME="/usr/local/hadoop"
HADOOP_COMMON_LIB_NATIVE_DIR="/usr/local/hadoop/lib/native"
HADOOP_OPTS="-Djava.library.path=/usr/local/hadoop/lib"
YARN_HOME="/usr/local/hadoop"
HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop"

```

environment의 찌꺼기 지우기(물결 붙은 파일)  

```
ls -alrt /etc/e*
sudo rm /etc/environment~
source /etc/environment
```

Hadoop 설치 확인

```
hadoop version
```

CLASSPATH에 할당했던 폴더 만들기  
```
mkdir ~/hadoop_user_jar
```
  

---

#### Hadoop 설정  
- core-site.xml  

```xml
<configuration>
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://localhost:9000</value>
	</property>
</configuration>
```

- hdfs-site.xml  
```xml
<configuration>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
</configuration>
```

- mapred-site.xml  
```
cp mapred-site.xml.template mapred-site.xml
```

```xml
<configuration>
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
</configuration>
```

- yarn-site.xml  

```xml
<configuration>

<!-- Site specific YARN configuration properties -->
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>

</configuration>

```

- hadoop-env.sh  
파일 맨 마지막에 추가  
원래 설정되어 있는 JAVA_HOME과 일치하도록 줄 것  

```
export JAVA_HOME="/usr/local/jdk_1.8.0_171"
export HADOOP_HOME="/usr/local/hadoop"
export HADOOP_MAPRED_HOME="/usr/local/hadoop"
export HADOOP_COMMON_HOME="/usr/local/hadoop"
export HADOOP_HDFS_HOME="/usr/local/hadoop"
export YARN_HOME="/usr/local/hadoop"
export YARN_CONF_DIR="/usr/local/hadoop/etc/hadoop"
export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop"
export HADOOP_OPTS="$HADOOP_OPTS -Djava.library.path=$HADOOP_HOME/lib/native"
export HADOOP_HOME_WARN_SUPPRESS="TRUE"
```

#### SSH 공개키 만들기  
```
ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa
cd ~/.ssh
cat id_rsa.pub >> authorized_keys
```

공개키 잘 작동하는지 확인
```
ssh localhost
```

#### daemon들이 돌아가고 있는지 확인  
  
daemon : background에서 돌아가는 process

```
jps
```

이렇게 나와야 한다.    

```
10386 SecondaryNameNode
10787 NodeManager
10202 DataNode
11070 Jps
10030 NameNode
10575 ResourceManager
```

---

#### Hadoop 실행 / 종료
namenode 초기화 (오류 없이 잘 작동하는지 확인)  
```
hadoop namenode -format
```

- 실행  
```
start-dfs.sh
start-yarn.sh
```

- 종료  
```
stop-dfs.sh
stop-yarn.sh
```

- 한꺼번에 시작 & 종료 (Deprecated)
```
start-all.sh
stop-all.sh
```

- 웹으로 보기  
http://localhost:50070


---

#### 리눅스 명령어들 
- 홈 디렉토리로 가기
```
cd
cd ~
```

- ssh 설치 되었는지 확인  
```
ps - ef | grep ssh
```

# 180601  

### 새 프로젝트 : DepartureDelay
```
new maven project  
maven quickstart  
Group Id : com.sist  
Artifact Id : DepartureDelay  
Package : com.sist  
```

```
AirlinePerformanceParser.java  

DepartureDelayCountMapper.java  
DepartureDelayCountReducer.java  
DepartureDelayCOunt.java
```

#### AirlinePerformanceParser

```java
package com.sist;

import org.apache.hadoop.io.Text;

/**
 * 항공 데이터 parser
 * @author sist
 *
 */
public class AirlinePerformanceParser {
	private int year;
	private int month;

	private int arriveDelayTime = 0; //도착 지연
	private int departureDelayTime = 0; //출발 지연
	private int distance = 0; //비행거리
	
	//NA 데이터 처리
	private boolean arriveDelayAvailable = true;
	private boolean departureDelayAvailable = true;
	private boolean distanceAvailable = true;
	
	private String uniqueCarrier; //항공사 코드
	
	public AirlinePerformanceParser(Text text) {
		try {
			String[] columns = text.toString().split(",");
			
			year = Integer.parseInt(columns[0]);
			month = Integer.parseInt(columns[1]);
			
			uniqueCarrier = columns[8];
			
			if(!columns[15].equals("NA")) {
				departureDelayTime = Integer.parseInt(columns[15]);
			} else {
				departureDelayAvailable = false;
			}

			if(!columns[14].equals("NA")) {
				arriveDelayTime = Integer.parseInt(columns[14]);
			} else {
				arriveDelayAvailable = false;
			}			

			if(!columns[18].equals("NA")) {
				distance = Integer.parseInt(columns[18]);
			} else {
				distanceAvailable = false;
			}		
			
		} catch (Exception e) {
			System.out.println("AirlinePerformanceParser parsing error:" + e.getMessage());
		}//--try-catch
		
	}

	public int getYear() {
		return year;
	}

	public int getMonth() {
		return month;
	}

	public int getArriveDelayTime() {
		return arriveDelayTime;
	}

	public int getDepartureDelayTime() {
		return departureDelayTime;
	}

	public int getDistance() {
		return distance;
	}

	public boolean isArriveDelayAvailable() {
		return arriveDelayAvailable;
	}

	public boolean isDepartureDelayAvailable() {
		return departureDelayAvailable;
	}

	public boolean isDistanceAvailable() {
		return distanceAvailable;
	}

	public String getUniqueCarrier() {
		return uniqueCarrier;
	}

}

```

참고  
```
Generate Getter and Setters에서 아래쪽 Code templates를 클릭하면
xml을 통해 getter/setter 모양을 만들어 줄 수 있다.  
```

#### DepartureDelayCountMapper  

```java
package com.sist;

import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;

import java.io.IOException;

public class DepartureDelayCountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {

	//map 출력 값
	private final IntWritable outputValue = new IntWritable(1);
	
	//map 출력 키
	private Text outputKey = new Text();
	@Override
	protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, IntWritable>.Context context)
			throws IOException, InterruptedException {

		AirlinePerformanceParser parser = new AirlinePerformanceParser(value);
		outputKey.set(parser.getYear() + "-" + parser.getMonth());
		
		if(parser.getDepartureDelayTime() > 0) {
			context.write(outputKey, outputValue);
		}
		
	}//--map

}

```


#### DepartureDelayCountReducer  

```java
package com.sist;

import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.io.Text;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;

/**
 * 
 * 1987-01:{1,1} -> 1987-01 {2}
 * @author sist
 *
 */
public class DepartureDelayCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {

	private IntWritable result = new IntWritable();
	
	@Override
	protected void reduce(Text key, Iterable<IntWritable> values,
			Reducer<Text, IntWritable, Text, IntWritable>.Context context) throws IOException, InterruptedException {
		
		int sum = 0;
		
		for(IntWritable value : values) {
			sum += value.get();
		}
		
		result.set(sum);
		
		context.write(key, result);
	}//--reduce

}

```


#### DepartureDelayCount

```java
package com.sist;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;

import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;

/**
 * 실행순서
 * 1. job 객체 생성
 * 2.job 객체에 map, reducer 정보를 설정
 * 3. job 실행
 * @author sist
 *
 */


public class DepartureDelayCount {

	public static void main(String[] args) throws Exception {
		Configuration conf = new Configuration();
		
		//1.job 객체 생성
		Job job = new Job(conf, "DepartureDelayCount");
		
		//1.1 (이미 존재한다면) output Dir 삭제
		FileSystem hdfs = FileSystem.get(conf);
		
		//filename
		Path outPath = new Path("/output");
		if(hdfs.exists(outPath)) {
			hdfs.delete(outPath, true);
		}
		
		//2.job 객체에 map, reducer 정보를 설정
		job.setJarByClass(DepartureDelayCount.class);
		job.setMapperClass(DepartureDelayCountMapper.class);
		job.setReducerClass(DepartureDelayCountReducer.class);
		
		//2.1. 입출력 data format
		job.setInputFormatClass(TextInputFormat.class);
		job.setOutputFormatClass(TextOutputFormat.class);
		
		//2.2.  출력 key / 출력 result
		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(IntWritable.class);
		
		//2.3. 입출력 data 경로
		FileInputFormat.addInputPath(job, new Path("/input"));
		FileOutputFormat.setOutputPath(job, outPath);
		
		//3. job 실행
		job.waitForCompletion(true);
		
	}//--main

}

```

이제 jar 파일로 내보내자.

---

#### Hadoop에서 실행  


```
hadoop namenode -format
start-dfs.sh
start-yarn.sh
```

```
jps
```

```
hdfs dfs -ls -R /
hdfs dfs -mkdir /input
cd hadoop_user_jar/
hdfs dfs -put airSample.txt
```

실행시킬 jar 파일과 메인 메소드 이름을 알려주자
```
hadoop jar DepartureDelayCount.jar com.sist.DepartureDelayCount
```

```
	Map-Reduce Framework
		Map input records=12
		Map output records=6

		...
		Reduce input groups=2
		Reduce shuffle bytes=90
	
```

실행되고 나서 여러 파일들이 생긴 것을 볼 수 있다.
```
hdfs dfs -ls -R /
```

결과 파일 열어보기
```
hdfs dfs -cat /output/part-r-00000
```
  
```
1987-10	5
1987-11	1
```


input에 파일이 2개이면
```
1987-10	10
1987-11	2

```

1987.csv로 해보면

```
1987-10	175568
1987-11	177218
1987-12	218858

```



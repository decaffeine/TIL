# 180604  
  
데이터 받아 놓은 폴더(dataexpo)에서 실행  
input 디렉토리를 만들고 거기에 모든 csv를 넣는다.

```
hdfs dfs -mkdir /input
hdfs dfs -put *.csv /input
```

디스크 용량 확인 (12GB)
```
du -h ./
hdfs dfs -du /input
```

jar 파일을 넣은 폴더에서 jar 파일 실행
```
hadoop jar DepartureDelayCount.jar com.sist.DepartureDelayCount
```

결과에서 볼 것들  
```
Map input records 
Map output records = Reduce input records
Reduce output records
```

get : hdfs 상의 파일을 일반 디렉토리로 내리기
```
hdfs dfs -ls -R /output
hdfs dfs -get /output/part-r-00000
```

gedit으로 part-r-00000 파일을 열어서 구경해보자.  


---

### 새 프로젝트 : ArrivalDelayCount

```
ArrivalDelayCountMapper.java
ArrivalDelayCountReducer.java
ArrivalDelayCount.java

AirlinePerformanceParser.java
```

DepartureDelayCount와 대부분 동일하다.  
ArrivalDelayCountMapper에서  
```java
		if(parser.getArriveDelayTime() > 0) {
			context.write(outputKey, outputValue);
		}
```

ArrivalDelayCount에서  

```java

		//1.job 객체 생성
		Job job = new Job(conf, "ArrivalDelayCount");
```

이 부분만 바꾸어 주면 된다.  

#### jar로 만들어 주기   
1. 프로젝트 오른쪽 버튼 클릭하고 export  
2. pom.xml에서 mainClass를 com.sist.ArrivalDelayCount로 설정  
```xml
                <configuration>
                    <mainClass>com.sist.ArrivalDelayCount</mainClass>
                </configuration>
```
Run As - Maven Build  
Goals : package  

---

### 사용자 정의 옵션
GenericOptionsParser가 제공하는 옵션 활용.  
(책 155페이지)

### 새 프로젝트 : DepartureArrivalDelayCount
Arrival과 Departure는 크게 다른 부분이 없는데 서로 다른 프로젝트를 2개나 만들어야 했다.  
GenericOptionsParser를 이용해 입력에 따라  
입력이 'departure'이면 departure를,  
입력이 'arrival'이면 arrival을 세게끔 만들어 보자.  

- AirlinePerformanceParser   
그대로 사용   

- DepartureArrivalDelayCountMapper  
```java
package com.sist;

import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.io.LongWritable;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;

public class DepartureArrivalDelayCountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {

	private String workType;
	
	private final static IntWritable one = new IntWritable(1);
	
	private Text outputKey = new Text();
	
	@Override
	protected void setup(Mapper<LongWritable, Text, Text, IntWritable>.Context context) 
			throws  IOException, InterruptedException {
		workType = context.getConfiguration().get("workType");
	}
	
	@Override
	protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, IntWritable>.Context context)
		throws IOException, InterruptedException
	{
		AirlinePerformanceParser parser = new AirlinePerformanceParser(value);
		
		if(workType.equalsIgnoreCase("departure")) { //출발지연
			if (parser.getDepartureDelayTime() > 0) {
				outputKey.set(parser.getYear() + "," + parser.getMonth()); //1987, 11
				context.write(outputKey, one);
			}
		}else if(workType.equalsIgnoreCase("arrival")) { //도착지연
			if (parser.getArriveDelayTime() > 0) {
				outputKey.set(parser.getYear() + "," + parser.getMonth()); //1987, 11
				context.write(outputKey, one);
			}
		}//--ifelse
		
	}
	
}

```

- DepartureArrivalDelayCountReducer
```java
package com.sist;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class DepartureArrivalDelayCountReducer extends  Reducer<Text, IntWritable, Text, IntWritable> {

	private IntWritable result = new IntWritable();
	
	@Override
	protected void reduce(Text key, Iterable<IntWritable> values,
			Reducer<Text, IntWritable, Text, IntWritable>.Context context) throws IOException, InterruptedException {
		
		int sum = 0;
		
		for(IntWritable value : values) {
			sum += value.get();
		}
		
		result.set(sum);
		
		context.write(key, result);
	}//--reduce
}

```

- DepartureArrivalDelayCount
```java
package com.sist;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;
import org.apache.hadoop.util.GenericOptionsParser;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;

import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;

import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.fs.Path;

public class DepartureArrivalDelayCount extends Configured implements Tool {

	@Override
	public int run(String[] args) throws Exception {
		String[] otherArgs = new GenericOptionsParser(getConf(),args).getRemainingArgs();
		if(otherArgs.length != 2) {
			System.out.println("Use DeparturArrivalDelayCount <in> <out>");
			System.exit(2);
		}
		
		Job job = new Job(getConf(), "DepartureArrivalDelayCount");
		
		//입출력 경로
		FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
		FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));
		
		//Job class
		job.setJarByClass(DepartureArrivalDelayCount.class);

		//Mapper
		job.setMapperClass(DepartureArrivalDelayCountMapper.class);
		
		//Reducer
		job.setReducerClass(DepartureArrivalDelayCountReducer.class);
		
		//입출력 데이터 포맷
		job.setInputFormatClass(TextInputFormat.class);
		job.setOutputFormatClass(TextOutputFormat.class);
		
		//출력 key, value
		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(IntWritable.class);
		
		job.waitForCompletion(true);
		
		
		return 0;
	}
	
	public static void main(String args[]) throws Exception {
		//tool inferface 실행
		int res = ToolRunner.run(new Configuration(), new DepartureArrivalDelayCount(), args);
		System.out.println("**res = " + res);
	}



}

```


터미널에서 실행  

```
hadoop jar DepartureArrivalDelayCount.jar com.sist.DepartureArrivalDelayCount -D workType=departure /input /output
```

### 새 프로젝트  : UserCounters  
지금까지는 출발 지연만 카운트했다면  
이제 정시 출발, 정시보다 일찍 출발, 출발 지연, 출발 정보 없음(NA)까지 모두 카운트해보자  

- Enum : DelayCounters  
```java
package com.sist;

public enum DelayCounters {
	/**
	 * not_available_arrival, scheduled_arrival, early_arrival,
	 * 도착정보가 NA, 정시 도착, 일찍 도착
	 */
	not_available_arrival, scheduled_arrival, early_arrival,
	not_available_departure, scheduled_departure, early_departure
	

}
```

- Mapper

```java
package com.sist;

import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.io.LongWritable;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;

public class DelayDepartureArrivalCountersMapper extends Mapper<LongWritable, Text, Text, IntWritable> {

	private String workType;
	
	private final static IntWritable one = new IntWritable(1);
	
	private Text outputKey = new Text();
	
	@Override
	protected void setup(Mapper<LongWritable, Text, Text, IntWritable>.Context context) 
			throws  IOException, InterruptedException {
		workType = context.getConfiguration().get("workType");
	}
	
	@Override
	protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, IntWritable>.Context context)
		throws IOException, InterruptedException
	{
		AirlinePerformanceParser parser = new AirlinePerformanceParser(value);
		
		if(workType.equalsIgnoreCase("departure")) { 
			if(parser.isDepartureDelayAvailable()){
				if (parser.getDepartureDelayTime() > 0) { //출발지연
					outputKey.set(parser.getYear() + "," + parser.getMonth()); //1987, 11
					context.write(outputKey, one);
				}else if (parser.getDepartureDelayTime() == 0){ //정시 출발
					context.getCounter(DelayCounters.scheduled_departure).increment(1);
				}else if (parser.getDepartureDelayTime() < 0) { //일찍 출발
					context.getCounter(DelayCounters.early_departure).increment(1);
				} 
			} else { //출발 지연이 NA
				context.getCounter(DelayCounters.not_available_departure).increment(1);
			}
			
			
		}else if(workType.equalsIgnoreCase("arrival")) { //도착지연
			if(parser.isArriveDelayAvailable()) {
				if (parser.getArriveDelayTime() > 0) {
					outputKey.set(parser.getYear() + "," + parser.getMonth()); //1987, 11
					context.write(outputKey, one);
				} else if (parser.getArriveDelayTime() == 0){
					context.getCounter(DelayCounters.scheduled_arrival).increment(1);
				} else if (parser.getArriveDelayTime() < 0) {
					context.getCounter(DelayCounters.early_arrival).increment(1);
				}
			
			} else {
				context.getCounter(DelayCounters.not_available_arrival).increment(1);
			}
		
	}
		
		
		}
	
	
	
}
```

- Reducer  

```java
package com.sist;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class DelayDepartureArrivalCountReducer extends  Reducer<Text, IntWritable, Text, IntWritable> {

	private IntWritable result = new IntWritable();
	
	@Override
	protected void reduce(Text key, Iterable<IntWritable> values,
			Reducer<Text, IntWritable, Text, IntWritable>.Context context) throws IOException, InterruptedException {
		
		int sum = 0;
		
		for(IntWritable value : values) {
			sum += value.get();
		}
		
		result.set(sum);
		
		context.write(key, result);
	}//--reduce
}


```

- DelayDepartureArrivalCount

```java
package com.sist;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;
import org.apache.hadoop.util.GenericOptionsParser;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;

import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;

import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.fs.Path;

public class DelayDepartureArrivalCount extends Configured implements Tool {

	@Override
	public int run(String[] args) throws Exception {
		String[] otherArgs = new GenericOptionsParser(getConf(),args).getRemainingArgs();
		if(otherArgs.length != 2) {
			System.out.println("Use DelayDeparturArrivalCount <in> <out>");
			System.exit(2);
		}
		
		Job job = new Job(getConf(), "DelayDepartureArrivalCount");
		
		//입출력 경로
		FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
		FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));
		
		//Job class
		job.setJarByClass(DelayDepartureArrivalCount.class);

		//Mapper
		job.setMapperClass(DelayDepartureArrivalCountersMapper.class);
		
		//Reducer
		job.setReducerClass(DelayDepartureArrivalCountReducer.class);
		
		//입출력 데이터 포맷
		job.setInputFormatClass(TextInputFormat.class);
		job.setOutputFormatClass(TextOutputFormat.class);
		
		//출력 key, value
		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(IntWritable.class);
		
		job.waitForCompletion(true);
		
		
		return 0;
	}
	
	public static void main(String args[]) throws Exception {
		//tool inferface 실행
		int res = ToolRunner.run(new Configuration(), new DelayDepartureArrivalCount(), args);
		System.out.println("**res = " + res);
	}



}

```


결과  

```
com.sist.DelayCounters  
		early_arrival=57893927
		not_available_arrival=2587529
		scheduled_arrival=5214344
```

### 새 프로젝트 : MultiOutput
departure랑 arrival 두 개를 동시에 출력  

- Mapper
```java
package com.sist;

import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.io.LongWritable;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;

public class DelayCountMultipleMapper extends Mapper<LongWritable, Text, Text, IntWritable> {

	private String workType;
	
	private final static IntWritable one = new IntWritable(1);
	
	private Text outputKey = new Text();
	
	@Override
	protected void setup(Mapper<LongWritable, Text, Text, IntWritable>.Context context) 
			throws  IOException, InterruptedException {
		workType = context.getConfiguration().get("workType");
	}
	
	@Override
	protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, IntWritable>.Context context)
		throws IOException, InterruptedException
	{
		AirlinePerformanceParser parser = new AirlinePerformanceParser(value);
		
			if(parser.isDepartureDelayAvailable()){
				if (parser.getDepartureDelayTime() > 0) { //출발지연
					outputKey.set("D," + parser.getYear() + "," + parser.getMonth()); //1987, 11
					context.write(outputKey, one);
				}else if (parser.getDepartureDelayTime() == 0){ //정시 출발
					context.getCounter(DelayCounters.scheduled_departure).increment(1);
				}else if (parser.getDepartureDelayTime() < 0) { //일찍 출발
					context.getCounter(DelayCounters.early_departure).increment(1);
				} 
			} else { //출발 지연이 NA
				context.getCounter(DelayCounters.not_available_departure).increment(1);
			}
			
			
 //도착지연
			if(parser.isArriveDelayAvailable()) {
				if (parser.getArriveDelayTime() > 0) {
					outputKey.set("A,"+parser.getYear() + "," + parser.getMonth()); //1987, 11
					context.write(outputKey, one);
				} else if (parser.getArriveDelayTime() == 0){
					context.getCounter(DelayCounters.scheduled_arrival).increment(1);
				} else if (parser.getArriveDelayTime() < 0) {
					context.getCounter(DelayCounters.early_arrival).increment(1);
				}
			
			} else {
				context.getCounter(DelayCounters.not_available_arrival).increment(1);
			}
		
	
		
		
		}
	
	
	
}


```


- Reducer
```java
package com.sist;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;

public class DelayCountMultipleReducer extends  Reducer<Text, IntWritable, Text, IntWritable> {

	private IntWritable result = new IntWritable();

	private Text outputKey = new Text();
	private MultipleOutputs<Text, IntWritable> mos;
	

	@Override
	protected void setup(Reducer<Text, IntWritable, Text, IntWritable>.Context context)
			throws IOException, InterruptedException {
		mos = new MultipleOutputs<Text, IntWritable>(context);
		
	}//--setup

	//D,1987,02,{1,1,1,1,1}
	//A,1988,01,{1,1,1,1}
	@Override
	protected void reduce(Text key, Iterable<IntWritable> values,
			Reducer<Text, IntWritable, Text, IntWritable>.Context context) throws IOException, InterruptedException {
		
		//data 구분자로 분리
		String[] columns = key.toString().split(",");
		
		outputKey.set(columns[1]+","+columns[2]); //1987,02
		
		if(columns[0].equals("D")) {
			int sum = 0;
			
			for(IntWritable value : values) {
				sum += value.get();
			}
			
			result.set(sum);
			
			mos.write("departure",  outputKey, result);
		}else {
			int sum = 0;
			
			for(IntWritable value : values) {
				sum += value.get();
			}
			
			result.set(sum);
			
			mos.write("arrival",  outputKey, result);
			
		}	
		
	}//--reduce

	@Override
	protected void cleanup(Reducer<Text, IntWritable, Text, IntWritable>.Context context)
			throws IOException, InterruptedException {
		mos.close();
	}
	
	
	
}

```


- Driver
```java
package com.sist;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;
import org.apache.hadoop.util.GenericOptionsParser;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;

import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;

import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.fs.Path;

public class DelayCountMultiple extends Configured implements Tool {

	@Override
	public int run(String[] args) throws Exception {
		String[] otherArgs = new GenericOptionsParser(getConf(),args).getRemainingArgs();
		if(otherArgs.length != 2) {
			System.out.println("Use DelayDeparturArrivalCount <in> <out>");
			System.exit(2);
		}
		
		Job job = new Job(getConf(), "DelayDepartureArrivalCount");
		
		//입출력 경로
		FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
		FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));
		
		//Job class
		job.setJarByClass(DelayCountMultiple.class);

		//Mapper
		job.setMapperClass(DelayCountMultipleMapper.class);
		
		//Reducer
		job.setReducerClass(DelayCountMultipleReducer.class);
		
		//입출력 데이터 포맷
		job.setInputFormatClass(TextInputFormat.class);
		job.setOutputFormatClass(TextOutputFormat.class);
		
		//출력 key, value
		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(IntWritable.class);
		
		//MultipleOutputs 설정
		MultipleOutputs.addNamedOutput(job, "departure", TextOutputFormat.class, 
																						Text.class, IntWritable.class);
		MultipleOutputs.addNamedOutput(job, "arrival", TextOutputFormat.class, 
				Text.class, IntWritable.class);

		job.waitForCompletion(true);
		
		
		return 0;
	}
	
	public static void main(String args[]) throws Exception {
		//tool inferface 실행
		int res = ToolRunner.run(new Configuration(), new DelayCountMultiple(), args);
		System.out.println("**res = " + res);
	}



}

```


- 실행  

```
hadoop jar MutliOutput-0.0.1-SNAPSHOT.jar com.sist.DelayCountMultiple /input /output 
```

- 결과  
```
	com.sist.DelayCounters
		early_arrival=57893927
		early_departure=44797705
		not_available_arrival=2587529
		not_available_departure=2302136
		scheduled_arrival=5214344
		scheduled_departure=26416800

-rw-r--r--   1 sist supergroup       3636 2018-06-04 12:37 /output/arrival-r-00000
-rw-r--r--   1 sist supergroup       3635 2018-06-04 12:37 /output/departure-r-00000

```
